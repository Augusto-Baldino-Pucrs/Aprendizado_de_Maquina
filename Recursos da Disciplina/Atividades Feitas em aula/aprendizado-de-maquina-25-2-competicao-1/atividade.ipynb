{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37be849",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# Kaggle - Classificação Coluna Vertebral\n",
    "# Modelos: KNN, Naïve Bayes, Decision Tree\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8361a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone  # Adicione esta importação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d11f49",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# 1. Carregamento dos dados\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e266085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# Remover coluna de índice, se existir\n",
    "if \"Unnamed: 0\" in train_df.columns:\n",
    "    train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n",
    "if \"Unnamed: 0\" in test_df.columns:\n",
    "    test_df = test_df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc649ce1",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# 2. Separar features e target\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4705435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=[\"class\"])\n",
    "y = train_df[\"class\"]\n",
    "\n",
    "# Codificar o alvo\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "041081fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição das classes no treino:\n",
      "2    105\n",
      "1     70\n",
      "0     42\n",
      "Name: count, dtype: int64\n",
      "Proporções: [0.48387097 0.32258065 0.19354839]\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 2.5 ANALISAR DISTRIBUIÇÃO DAS CLASSES\n",
    "# ======================================\n",
    "print(\"Distribuição das classes no treino:\")\n",
    "print(pd.Series(y_encoded).value_counts())\n",
    "print(f\"Proporções: {pd.Series(y_encoded).value_counts(normalize=True).values}\")\n",
    "\n",
    "# Verificar se há desbalanceamento severo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e86062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ANÁLISE DETALHADA POR CLASSE:\n",
      "\n",
      "--- Hernia ---\n",
      "Quantidade: 42\n",
      "Estatísticas de degree_spondylolisthesis:\n",
      "  Mínimo: -10.68\n",
      "  Máximo: 15.78\n",
      "  Média: 2.27\n",
      "  Mediana: 2.68\n",
      "\n",
      "--- Normal ---\n",
      "Quantidade: 70\n",
      "Estatísticas de degree_spondylolisthesis:\n",
      "  Mínimo: -11.06\n",
      "  Máximo: 31.17\n",
      "  Média: 2.34\n",
      "  Mediana: 1.15\n",
      "\n",
      "--- Spondylolisthesis ---\n",
      "Quantidade: 105\n",
      "Estatísticas de degree_spondylolisthesis:\n",
      "  Mínimo: 1.01\n",
      "  Máximo: 418.54\n",
      "  Média: 54.81\n",
      "  Mediana: 49.70\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 2.6 ANÁLISE DETALHADA POR CLASSE\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"ANÁLISE DETALHADA POR CLASSE:\")\n",
    "\n",
    "for class_idx, class_name in enumerate(label_encoder.classes_):\n",
    "    class_mask = (y_encoded == class_idx)\n",
    "    class_data = X[class_mask]\n",
    "    \n",
    "    print(f\"\\n--- {class_name} ---\")\n",
    "    print(f\"Quantidade: {class_mask.sum()}\")\n",
    "    print(\"Estatísticas de degree_spondylolisthesis:\")\n",
    "    print(f\"  Mínimo: {class_data['degree_spondylolisthesis'].min():.2f}\")\n",
    "    print(f\"  Máximo: {class_data['degree_spondylolisthesis'].max():.2f}\")\n",
    "    print(f\"  Média: {class_data['degree_spondylolisthesis'].mean():.2f}\")\n",
    "    print(f\"  Mediana: {class_data['degree_spondylolisthesis'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe642322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ANÁLISE DE DISTRIBUIÇÃO TREINO vs TESTE\n",
      "\n",
      "Estatísticas das features no TREINO:\n",
      "       degree_spondylolisthesis  sacral_slope\n",
      "count                217.000000    217.000000\n",
      "mean                  27.715448     42.916988\n",
      "std                   40.965137     13.631236\n",
      "min                  -11.058179     13.516568\n",
      "25%                    1.517203     33.366366\n",
      "50%                   13.683047     42.447102\n",
      "75%                   49.159426     51.766175\n",
      "max                  418.543082    121.429566\n",
      "\n",
      "Estatísticas das features no TESTE:\n",
      "       degree_spondylolisthesis  sacral_slope\n",
      "count                 93.000000     93.000000\n",
      "mean                  22.986269     43.039797\n",
      "std                   27.968445     12.996425\n",
      "min                   -7.825986     13.366931\n",
      "25%                    1.913307     33.091700\n",
      "50%                   10.832011     42.137595\n",
      "75%                   38.538741     53.530766\n",
      "max                  148.753711     78.794052\n",
      "\n",
      "⚠️  ENCONTRADOS 2 OUTLIERS NO TESTE:\n",
      "    degree_spondylolisthesis  sacral_slope\n",
      "48                101.719092     53.972627\n",
      "64                148.753711     23.875281\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 2.7 ANÁLISE DE DISTRIBUIÇÃO ENTRE TREINO E TESTE\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"ANÁLISE DE DISTRIBUIÇÃO TREINO vs TESTE\")\n",
    "\n",
    "# Verificar se há diferenças significativas nas distribuições\n",
    "print(\"\\nEstatísticas das features no TREINO:\")\n",
    "print(X[['degree_spondylolisthesis', 'sacral_slope']].describe())\n",
    "\n",
    "print(\"\\nEstatísticas das features no TESTE:\")\n",
    "print(test_df[['degree_spondylolisthesis', 'sacral_slope']].describe())\n",
    "\n",
    "# Verificar outliers extremos no teste\n",
    "test_outliers = test_df[test_df['degree_spondylolisthesis'] > 100]  # Valores muito altos\n",
    "if len(test_outliers) > 0:\n",
    "    print(f\"\\n⚠️  ENCONTRADOS {len(test_outliers)} OUTLIERS NO TESTE:\")\n",
    "    print(test_outliers[['degree_spondylolisthesis', 'sacral_slope']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4202b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ANÁLISE DETALHADA DA MUDANÇA TEMPORAL\n",
      "\n",
      "Percentis do degree_spondylolisthesis (Treino vs Teste):\n",
      "P0: Treino=-11.1 vs Teste=-7.8\n",
      "P10: Treino=-2.2 vs Teste=-1.7\n",
      "P25: Treino=1.5 vs Teste=1.9\n",
      "P50: Treino=13.7 vs Teste=10.8\n",
      "P75: Treino=49.2 vs Teste=38.5\n",
      "P90: Treino=69.4 vs Teste=56.7\n",
      "P95: Treino=89.0 vs Teste=73.8\n",
      "P99: Treino=123.9 vs Teste=105.5\n",
      "P100: Treino=418.5 vs Teste=148.8\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 2.8 ANÁLISE DETALHADA DOS OUTLIERS E MUDANÇA DE DISTRIBUIÇÃO\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"ANÁLISE DETALHADA DA MUDANÇA TEMPORAL\")\n",
    "\n",
    "# Analisar a distribuição por percentis\n",
    "print(\"\\nPercentis do degree_spondylolisthesis (Treino vs Teste):\")\n",
    "percentis = [0, 10, 25, 50, 75, 90, 95, 99, 100]\n",
    "for p in percentis:\n",
    "    treino_p = np.percentile(X['degree_spondylolisthesis'], p)\n",
    "    teste_p = np.percentile(test_df['degree_spondylolisthesis'], p)\n",
    "    print(f\"P{p}: Treino={treino_p:.1f} vs Teste={teste_p:.1f}\")\n",
    "\n",
    "# O teste tem valores significativamente diferentes nos percentis altos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f780d6c",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# 3. Padronização dos dados\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "698271ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test_df)\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e6c8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "APLICANDO PRÉ-PROCESSAMENTO ROBUSTO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pré-processamento robusto aplicado com winsorization\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 3.1 PRÉ-PROCESSAMENTO ROBUSTO\n",
    "# ======================================\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"APLICANDO PRÉ-PROCESSAMENTO ROBUSTO\")\n",
    "\n",
    "# Usar RobustScaler que é menos sensível a outliers\n",
    "robust_scaler = RobustScaler()\n",
    "X_robust = robust_scaler.fit_transform(X)\n",
    "test_robust = robust_scaler.transform(test_df)\n",
    "\n",
    "# Aplicar winsorization para lidar com outliers extremos\n",
    "def winsorize_features(X_array, limits=(0.01, 0.01)):\n",
    "    \"\"\"Aplica winsorization para limitar outliers\"\"\"\n",
    "    from scipy.stats.mstats import winsorize\n",
    "    X_winsorized = X_array.copy()\n",
    "    for i in range(X_array.shape[1]):\n",
    "        X_winsorized[:, i] = winsorize(X_array[:, i], limits=limits)\n",
    "    return X_winsorized\n",
    "\n",
    "# Aplicar apenas no degree_spondylolisthesis (que tem outliers extremos)\n",
    "degree_idx = X.columns.get_loc('degree_spondylolisthesis')\n",
    "X_robust[:, degree_idx] = winsorize_features(X_robust[:, degree_idx:degree_idx+1], limits=(0.05, 0.05)).flatten()\n",
    "test_robust[:, degree_idx] = winsorize_features(test_robust[:, degree_idx:degree_idx+1], limits=(0.05, 0.05)).flatten()\n",
    "\n",
    "print(\"Pré-processamento robusto aplicado com winsorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3650acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PRÉ-PROCESSAMENTO SUPER CONSERVADOR\n",
      "Bins criados: [-0.38161537 -0.27688602 -0.16383357  0.2859399   0.80169857  1.64442853]\n",
      "Distribuição treino discretizado: [43 43 44 40 36 11]\n",
      "Distribuição teste discretizado: [19 19 18 22 15]\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 3.2 PRÉ-PROCESSAMENTO MAIS AGRESSIVO\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"PRÉ-PROCESSAMENTO SUPER CONSERVADOR\")\n",
    "\n",
    "# Estratégia: Discretizar a feature problemática em bins\n",
    "def discretize_degree_feature(X_array, test_array, n_bins=5):\n",
    "    \"\"\"Discretiza degree_spondylolisthesis para reduzir sensibilidade a outliers\"\"\"\n",
    "    degree_values = np.concatenate([X_array, test_array])\n",
    "    bins = np.percentile(degree_values, [0, 20, 40, 60, 80, 100])\n",
    "    \n",
    "    X_discrete = X_array.copy()\n",
    "    test_discrete = test_array.copy()\n",
    "    \n",
    "    X_discrete = np.digitize(X_array, bins) - 1  # 0-indexed\n",
    "    test_discrete = np.digitize(test_array, bins) - 1\n",
    "    \n",
    "    return X_discrete, test_discrete, bins\n",
    "\n",
    "# Aplicar apenas na feature problemática\n",
    "degree_idx = X.columns.get_loc('degree_spondylolisthesis')\n",
    "X_degree = X_robust[:, degree_idx]\n",
    "test_degree = test_robust[:, degree_idx]\n",
    "\n",
    "X_degree_disc, test_degree_disc, bins = discretize_degree_feature(X_degree, test_degree, n_bins=4)\n",
    "\n",
    "print(f\"Bins criados: {bins}\")\n",
    "print(f\"Distribuição treino discretizado: {np.bincount(X_degree_disc)}\")\n",
    "print(f\"Distribuição teste discretizado: {np.bincount(test_degree_disc)}\")\n",
    "\n",
    "# Substituir nos arrays\n",
    "X_conservative = X_robust.copy()\n",
    "test_conservative = test_robust.copy()\n",
    "X_conservative[:, degree_idx] = X_degree_disc\n",
    "test_conservative[:, degree_idx] = test_degree_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfe8b5",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# 4. Treinamento e Validação\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b166963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Treinando KNN...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros KNN: {'metric': 'manhattan', 'n_neighbors': 25, 'weights': 'uniform'}\n",
      "Acurácia KNN: 0.8252642706131079\n",
      "==================================================\n",
      "Treinando Naïve Bayes...\n",
      "Melhores parâmetros Naïve Bayes: {'var_smoothing': 1e-07}\n",
      "Acurácia Naïve Bayes: 0.8433403805496829\n",
      "==================================================\n",
      "Treinando Decision Tree...\n",
      "Melhores parâmetros Decision Tree: {'ccp_alpha': 0.01, 'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 10}\n",
      "Acurácia Decision Tree: 0.7697674418604652\n",
      "\n",
      "Melhor modelo: Naïve Bayes com acurácia: 0.8433\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 4. Treinamento e Validação - SEM RANDOM FOREST\n",
    "# ======================================\n",
    "\n",
    "# ----- Modelo 1: KNN -----\n",
    "print(\"=\" * 50)\n",
    "print(\"Treinando KNN...\")\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [25, 27, 29, 31, 33, 35],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['manhattan']\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, param_grid_knn, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
    "grid_knn.fit(X_scaled, y_encoded)\n",
    "print(\"Melhores parâmetros KNN:\", grid_knn.best_params_)\n",
    "print(\"Acurácia KNN:\", grid_knn.best_score_)\n",
    "\n",
    "# ----- Modelo 2: Naïve Bayes -----\n",
    "print(\"=\" * 50)\n",
    "print(\"Treinando Naïve Bayes...\")\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "nb = GaussianNB()\n",
    "grid_nb = GridSearchCV(nb, param_grid_nb, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
    "grid_nb.fit(X_scaled, y_encoded)\n",
    "print(\"Melhores parâmetros Naïve Bayes:\", grid_nb.best_params_)\n",
    "print(\"Acurácia Naïve Bayes:\", grid_nb.best_score_)\n",
    "\n",
    "# ----- Modelo 3: Decision Tree -----\n",
    "print(\"=\" * 50)\n",
    "print(\"Treinando Decision Tree...\")\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [2, 3],\n",
    "    'min_samples_split': [10, 15, 20],\n",
    "    'min_samples_leaf': [5, 7, 10],\n",
    "    'max_features': ['sqrt'],\n",
    "    'ccp_alpha': [0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
    "grid_dt.fit(X_scaled, y_encoded)\n",
    "print(\"Melhores parâmetros Decision Tree:\", grid_dt.best_params_)\n",
    "print(\"Acurácia Decision Tree:\", grid_dt.best_score_)\n",
    "\n",
    "# Comparação dos modelos\n",
    "modelos_comparacao = {\n",
    "    'KNN': grid_knn.best_score_,\n",
    "    'Naïve Bayes': grid_nb.best_score_,\n",
    "    'Decision Tree': grid_dt.best_score_\n",
    "}\n",
    "\n",
    "melhor_modelo_nome = max(modelos_comparacao, key=modelos_comparacao.get)\n",
    "print(f\"\\nMelhor modelo: {melhor_modelo_nome} com acurácia: {modelos_comparacao[melhor_modelo_nome]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2120422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TREINAMENTO COM VALIDAÇÃO TEMPORAL\n",
      "Usando TimeSeriesSplit para validação mais realista\n",
      "Acurácia Naïve Bayes (validação temporal): 0.7000\n",
      "Desvio padrão: 0.3055\n",
      "Acurácia com 2 features (temporal): 0.3778\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 4.1 MODELAGEM COM VALIDAÇÃO TEMPORAL\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"TREINAMENTO COM VALIDAÇÃO TEMPORAL\")\n",
    "\n",
    "# Ordenar os dados por degree_spondylolisthesis (simula ordenação temporal)\n",
    "sorted_indices = np.argsort(X['degree_spondylolisthesis'])\n",
    "X_sorted = X_robust[sorted_indices]\n",
    "y_sorted = y_encoded[sorted_indices]\n",
    "\n",
    "# Usar TimeSeriesSplit para validação mais realista\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(\"Usando TimeSeriesSplit para validação mais realista\")\n",
    "\n",
    "# ----- Naïve Bayes com validação temporal -----\n",
    "nb_temporal = GaussianNB(var_smoothing=1e-4)  # Mais regularização\n",
    "scores_temporal = cross_val_score(nb_temporal, X_sorted, y_sorted, cv=tscv, scoring='accuracy')\n",
    "\n",
    "print(f\"Acurácia Naïve Bayes (validação temporal): {scores_temporal.mean():.4f}\")\n",
    "print(f\"Desvio padrão: {scores_temporal.std():.4f}\")\n",
    "\n",
    "# Testar também com as 2 features mais importantes\n",
    "X_important_temporal = X_robust[:, [X.columns.get_loc('degree_spondylolisthesis'), \n",
    "                                   X.columns.get_loc('sacral_slope')]]\n",
    "scores_temporal_important = cross_val_score(nb_temporal, X_important_temporal, y_sorted, \n",
    "                                          cv=tscv, scoring='accuracy')\n",
    "\n",
    "print(f\"Acurácia com 2 features (temporal): {scores_temporal_important.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a84d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TREINAMENTO DO MODELO FINAL OTIMIZADO\n",
      "Acurácia Random Forest (5-fold CV): 0.8342 ± 0.0440\n",
      "\n",
      "Importância das features no Random Forest:\n",
      "                    Feature  Importance\n",
      "5  degree_spondylolisthesis    0.357051\n",
      "3              sacral_slope    0.208142\n",
      "2     lumbar_lordosis_angle    0.141892\n",
      "0          pelvic_incidence    0.140195\n",
      "4             pelvic_radius    0.113927\n",
      "1               pelvic_tilt    0.038793\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 4.2 MODELO FINAL MELHORADO\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"TREINAMENTO DO MODELO FINAL OTIMIZADO\")\n",
    "\n",
    "# Usar Random Forest simples mas eficaz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Usar todas as features mas com pré-processamento robusto\n",
    "X_rf = X_conservative\n",
    "test_rf = test_conservative\n",
    "\n",
    "# Validação cruzada\n",
    "scores_rf = cross_val_score(rf_model, X_rf, y_encoded, \n",
    "                          cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                          scoring='accuracy')\n",
    "\n",
    "print(f\"Acurácia Random Forest (5-fold CV): {scores_rf.mean():.4f} ± {scores_rf.std():.4f}\")\n",
    "\n",
    "# Treinar o modelo final\n",
    "rf_model.fit(X_rf, y_encoded)\n",
    "\n",
    "# Verificar importância das features\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nImportância das features no Random Forest:\")\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc628dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ANÁLISE DE OVERFITTING DETALHADA\n",
      "KNN - Treino: 0.8433, Validação: 0.8253, Diferença: 0.0181\n",
      "Naïve Bayes - Treino: 0.8710, Validação: 0.8433, Diferença: 0.0276\n",
      "Decision Tree - Treino: 0.7788, Validação: 0.7698, Diferença: 0.0090\n",
      "\n",
      "=== MODELO SELECIONADO ===\n",
      "Modelo: Naïve Bayes\n",
      "Acurácia validação: 0.8433\n",
      "Overfitting: 0.0276\n",
      "Score final: 0.8212\n"
     ]
    }
   ],
   "source": [
    "# ========== ANÁLISE DE OVERFITTING - SEM RANDOM FOREST ==========\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANÁLISE DE OVERFITTING DETALHADA\")\n",
    "\n",
    "models = {\n",
    "    'KNN': grid_knn.best_estimator_,\n",
    "    'Naïve Bayes': grid_nb.best_estimator_, \n",
    "    'Decision Tree': grid_dt.best_estimator_\n",
    "}\n",
    "\n",
    "diferencas = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_scaled, y_encoded)\n",
    "    train_score = model.score(X_scaled, y_encoded)\n",
    "    val_score = modelos_comparacao[name]\n",
    "    diferenca = train_score - val_score\n",
    "    diferencas[name] = diferenca\n",
    "    print(f\"{name} - Treino: {train_score:.4f}, Validação: {val_score:.4f}, Diferença: {diferenca:.4f}\")\n",
    "\n",
    "# Selecionar modelo com melhor trade-off\n",
    "scores_finais = {}\n",
    "for modelo in modelos_comparacao:\n",
    "    penalty = diferencas[modelo] * 0.8\n",
    "    scores_finais[modelo] = modelos_comparacao[modelo] - penalty\n",
    "\n",
    "melhor_modelo_final = max(scores_finais, key=scores_finais.get)\n",
    "print(f\"\\n=== MODELO SELECIONADO ===\")\n",
    "print(f\"Modelo: {melhor_modelo_final}\")\n",
    "print(f\"Acurácia validação: {modelos_comparacao[melhor_modelo_final]:.4f}\")\n",
    "print(f\"Overfitting: {diferencas[melhor_modelo_final]:.4f}\")\n",
    "print(f\"Score final: {scores_finais[melhor_modelo_final]:.4f}\")\n",
    "\n",
    "# Garantir overfitting baixo\n",
    "if diferencas[melhor_modelo_final] > 0.05:\n",
    "    print(f\"\\n⚠️  ALERTA: Overfitting alto ({diferencas[melhor_modelo_final]:.4f}).\")\n",
    "    melhor_modelo_final = min(diferencas, key=diferencas.get)\n",
    "    print(f\"Usando instead: {melhor_modelo_final} (overfitting: {diferencas[melhor_modelo_final]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee3faa",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# 5. Escolher o melhor modelo e treinar\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf6daef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo selecionado para submissão: GaussianNB\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 5. Escolher o melhor modelo e treinar\n",
    "# ======================================\n",
    "\n",
    "# Selecionar o melhor modelo com base na análise de overfitting\n",
    "if melhor_modelo_final == 'KNN':\n",
    "    melhor_modelo = grid_knn.best_estimator_\n",
    "elif melhor_modelo_final == 'Naïve Bayes':\n",
    "    melhor_modelo = grid_nb.best_estimator_\n",
    "elif melhor_modelo_final == 'Decision Tree':\n",
    "    melhor_modelo = grid_dt.best_estimator_\n",
    "\n",
    "# Treinar o modelo selecionado\n",
    "melhor_modelo.fit(X_scaled, y_encoded)\n",
    "\n",
    "print(f\"\\nModelo selecionado para submissão: {type(melhor_modelo).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "343e82f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SELEÇÃO OTIMIZADA DE FEATURES\n",
      "Usando apenas 2 features: ['degree_spondylolisthesis', 'sacral_slope']\n",
      "Acurácia com 2 features: 0.8252\n",
      "Overfitting com 2 features: 0.0043\n",
      "✅ Usando modelo simplificado com 2 features\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 5.1 Seleção de Features OTIMIZADA\n",
    "# ======================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SELEÇÃO OTIMIZADA DE FEATURES\")\n",
    "\n",
    "# Usar apenas as 2 features mais importantes\n",
    "top_2_features = ['degree_spondylolisthesis', 'sacral_slope']\n",
    "print(f\"Usando apenas 2 features: {top_2_features}\")\n",
    "\n",
    "X_important = X[top_2_features]\n",
    "X_important_scaled = scaler.fit_transform(X_important)\n",
    "test_important_scaled = scaler.transform(test_df[top_2_features])\n",
    "\n",
    "# Re-treinar o melhor modelo com 2 features\n",
    "melhor_modelo_simplificado = clone(models[melhor_modelo_final])\n",
    "scores_simplificado = cross_val_score(melhor_modelo_simplificado, X_important_scaled, y_encoded,\n",
    "                                    cv=cv_strategy, scoring='accuracy')\n",
    "\n",
    "print(f\"Acurácia com 2 features: {scores_simplificado.mean():.4f}\")\n",
    "\n",
    "# Treinar final\n",
    "melhor_modelo_simplificado.fit(X_important_scaled, y_encoded)\n",
    "\n",
    "# Verificar overfitting\n",
    "train_score_simple = melhor_modelo_simplificado.score(X_important_scaled, y_encoded)\n",
    "val_score_simple = scores_simplificado.mean()\n",
    "\n",
    "print(f\"Overfitting com 2 features: {train_score_simple - val_score_simple:.4f}\")\n",
    "\n",
    "# Decidir qual modelo usar\n",
    "if (train_score_simple - val_score_simple) < (diferencas[melhor_modelo_final] * 0.7):\n",
    "    print(\"✅ Usando modelo simplificado com 2 features\")\n",
    "    modelo_final = melhor_modelo_simplificado\n",
    "    features_finais = top_2_features\n",
    "    X_final_scaled = X_important_scaled\n",
    "    test_final_scaled = test_important_scaled\n",
    "    acuracia_esperada = val_score_simple\n",
    "else:\n",
    "    print(\"✅ Usando modelo completo\")\n",
    "    modelo_final = models[melhor_modelo_final]\n",
    "    features_finais = X.columns.tolist()\n",
    "    X_final_scaled = X_scaled\n",
    "    test_final_scaled = test_scaled\n",
    "    acuracia_esperada = modelos_comparacao[melhor_modelo_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c89efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "IMPLEMENTANDO ENSEMBLE CONSERVADOR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Ensemble: 0.8574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;nb&#x27;, GaussianNB(var_smoothing=0.0001)),\n",
       "                             (&#x27;dt&#x27;,\n",
       "                              DecisionTreeClassifier(max_depth=2,\n",
       "                                                     min_samples_leaf=10,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;knn&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
       "                                                   n_neighbors=35))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;nb&#x27;, GaussianNB(var_smoothing=0.0001)),\n",
       "                             (&#x27;dt&#x27;,\n",
       "                              DecisionTreeClassifier(max_depth=2,\n",
       "                                                     min_samples_leaf=10,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;knn&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;manhattan&#x27;,\n",
       "                                                   n_neighbors=35))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>nb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=0.0001)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, min_samples_leaf=10, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=35)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('nb', GaussianNB(var_smoothing=0.0001)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(max_depth=2,\n",
       "                                                     min_samples_leaf=10,\n",
       "                                                     random_state=42)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(metric='manhattan',\n",
       "                                                   n_neighbors=35))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================\n",
    "# 5.2 ENSEMBLE SIMPLES PARA MELHOR GENERALIZAÇÃO\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"IMPLEMENTANDO ENSEMBLE CONSERVADOR\")\n",
    "\n",
    "# Criar ensemble de modelos conservadores\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Modelos muito conservadores\n",
    "model1 = GaussianNB(var_smoothing=1e-4)\n",
    "model2 = DecisionTreeClassifier(max_depth=2, min_samples_leaf=10, random_state=42)\n",
    "model3 = KNeighborsClassifier(n_neighbors=35, weights='uniform', metric='manhattan')\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('nb', model1),\n",
    "        ('dt', model2),\n",
    "        ('knn', model3)\n",
    "    ],\n",
    "    voting='soft'  # Voting suave para probabilidades\n",
    ")\n",
    "\n",
    "# Validação do ensemble\n",
    "scores_ensemble = cross_val_score(ensemble, X_robust, y_encoded, \n",
    "                                cv=cv_strategy, scoring='accuracy')\n",
    "\n",
    "print(f\"Acurácia do Ensemble: {scores_ensemble.mean():.4f}\")\n",
    "\n",
    "# Treinar ensemble final\n",
    "ensemble.fit(X_robust, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3db710af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VALIDAÇÃO FINAL COM HOLDOUT\n",
      "Acurácia no holdout validation: 0.8864\n",
      "✅ Modelo com boa performance no holdout\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 5.4 VALIDAÇÃO COM HOLDOUT CONSERVADOR\n",
    "# ======================================\n",
    "print(\"=\" * 50)\n",
    "print(\"VALIDAÇÃO FINAL COM HOLDOUT\")\n",
    "\n",
    "# Criar um holdout conservador (20% dos dados)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_holdout, X_val, y_holdout, y_val = train_test_split(\n",
    "    X_rf, y_encoded, test_size=0.2, \n",
    "    stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar no holdout\n",
    "rf_model.fit(X_holdout, y_holdout)\n",
    "\n",
    "# Prever no validation set\n",
    "val_preds = rf_model.predict(X_val)\n",
    "val_accuracy = np.mean(val_preds == y_val)\n",
    "\n",
    "print(f\"Acurácia no holdout validation: {val_accuracy:.4f}\")\n",
    "\n",
    "# Se a acurácia for boa, usar este modelo\n",
    "if val_accuracy >= 0.80:\n",
    "    print(\"✅ Modelo com boa performance no holdout\")\n",
    "    final_model = rf_model\n",
    "    test_data = test_rf\n",
    "else:\n",
    "    print(\"⚠️  Performance no holdout baixa. Usando modelo anterior...\")\n",
    "    final_model = rf_model  # Usar mesmo assim\n",
    "    test_data = test_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff8113",
   "metadata": {},
   "source": [
    "# ======================================\n",
    "# 6. Gerar previsão no conjunto de teste\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f59932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GERANDO SUBMISSÃO FINAL COM AJUSTE\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fazer previsões com probabilidades\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(final_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     probs \u001b[38;5;241m=\u001b[39m final_model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mtest_final\u001b[49m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbabilidades shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Distribuição esperada do treino\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_final' is not defined"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 6. Gerar previsão no conjunto de teste - VERSÃO CORRIGIDA\n",
    "# ======================================\n",
    "\n",
    "print(f\"\\n=== PERFORMANCE FINAL ===\")\n",
    "print(f\"Acurácia no treino: {train_score_simple:.4f}\")\n",
    "print(f\"Acurácia na validação: {val_score_simple:.4f}\")\n",
    "print(f\"Diferença (overfitting): {train_score_simple - val_score_simple:.4f}\")\n",
    "\n",
    "# Fazer previsões com o modelo final\n",
    "predictions = modelo_final.predict(test_final_scaled)\n",
    "pred_labels = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# Criar arquivo de submissão\n",
    "submission = sample_submission.copy()\n",
    "submission[\"class\"] = pred_labels\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(f\"\\nArquivo 'submission.csv' gerado com sucesso!\")\n",
    "print(f\"Modelo utilizado: {type(modelo_final).__name__}\")\n",
    "print(f\"Features utilizadas: {features_finais}\")\n",
    "print(f\"Acurácia esperada: {acuracia_esperada:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
